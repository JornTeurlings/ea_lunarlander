{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from genepro.node_impl import *\n",
    "from genepro.evo import Evolution, OptimizationBehavior\n",
    "from genepro.node_impl import Constant\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "\n",
    "from joblib.parallel import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Logical CPU cores: 20\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "n_cores = cpu_count()\n",
    "print(f'Number of Logical CPU cores: {n_cores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\"Transition\", (\"state\", \"action\", \"next_state\", \"reward\"))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "        self.memory += other.memory\n",
    "        return self\n",
    "\n",
    "    def __add__(self, other):\n",
    "        self.memory = self.memory + other.memory\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "def fitness_function_pt(\n",
    "    multitree, num_episodes=5, episode_duration=300, render=False, ignore_done=False\n",
    "):\n",
    "    memory = ReplayMemory(10000)\n",
    "    rewards = []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        # get initial state of the environment\n",
    "        observation = env.reset()\n",
    "        observation = observation[0]\n",
    "\n",
    "        for _ in range(episode_duration):\n",
    "            if render:\n",
    "                frames.append(env.render())\n",
    "\n",
    "            input_sample = torch.from_numpy(observation.reshape((1, -1))).float()\n",
    "\n",
    "            # what goes here? TODO\n",
    "            action = torch.argmax(multitree.get_output_pt(input_sample))\n",
    "            observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "            rewards.append(reward)\n",
    "            output_sample = torch.from_numpy(observation.reshape((1, -1))).float()\n",
    "            memory.push(\n",
    "                input_sample,\n",
    "                torch.tensor([[action.item()]]),\n",
    "                output_sample,\n",
    "                torch.tensor([reward]),\n",
    "            )\n",
    "            if (terminated or truncated) and not ignore_done:\n",
    "                break\n",
    "\n",
    "    fitness = np.sum(rewards)\n",
    "\n",
    "    return fitness, memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self adaptation in coefficient mutation\n",
    "\n",
    "adding an additional parameter $\\sigma$ is added to the constant node.  \n",
    "\n",
    "$\\sigma = \\max\\left(\\exp(N(0,\\gamma^2)), \\epsilon\\right)$\n",
    "\n",
    "$c' = N(c, \\sigma^2)$\n",
    "\n",
    "$\\sigma ' = \\max(\\sigma \\exp(N(0,\\gamma^2)), \\epsilon)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genepro.multitree import Multitree\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class AdaptiveConstant(Constant):\n",
    "    def __init__(self, value: float = None):\n",
    "        super().__init__(value)\n",
    "        # self.gamma = gamma\n",
    "        # self.epsilon = epsilon\n",
    "        self.sigma = (\n",
    "            1.0  # np.max([np.exp(self.gamma * np.random.randn()), self.epsilon])\n",
    "        )\n",
    "\n",
    "    def set_sigma(self, sigma):\n",
    "        self.sigma = sigma\n",
    "\n",
    "\n",
    "def coeff_adaptive_mutation(\n",
    "    multitree: Multitree,\n",
    "    prob_coeff_mut: float = 0.25,\n",
    "    gamma: float = 0.1,\n",
    "    epsilon: float = 1e-16,\n",
    ") -> Node:\n",
    "    \"\"\"\n",
    "    Applies random coefficient mutations to constant nodes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : Node\n",
    "      the tree to which coefficient mutations are applied\n",
    "    prob_coeff_mut : float, optional\n",
    "      the probability with which coefficients are mutated (default is 0.25)\n",
    "    temp : float, optional\n",
    "      \"temperature\" that indicates the strength of coefficient mutation, it is relative to the current value (i.e., v' = v + temp*abs(v)*N(0,1))\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Node\n",
    "      the tree after coefficient mutation (it is the same as the tree in input)\n",
    "    \"\"\"\n",
    "    r = np.random.randint(multitree.n_trees)\n",
    "    tree = multitree.children[r]\n",
    "    coeffs = [n for n in tree.get_subtree() if type(n) == Constant]\n",
    "    for c in coeffs:\n",
    "        # decide wheter it should be applied\n",
    "        if np.random.uniform() < prob_coeff_mut:\n",
    "            v = c.get_value()\n",
    "            # update the value by +- sigma*N(0,1)\n",
    "            new_sigma = np.max([c.sigma * np.exp(gamma * np.random.randn()), epsilon])\n",
    "            c.set_sigma(new_sigma)\n",
    "\n",
    "            new_v = v + c.sigma * np.random.randn()\n",
    "\n",
    "            c.set_value(new_v)\n",
    "\n",
    "    multitree.children[r] = tree\n",
    "    return multitree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from copy import deepcopy\n",
    "from joblib.parallel import Parallel, delayed\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def paralel_tournament_selection(contestants : list, num_to_select : int, tournament_size : int=4) -> list:\n",
    "  \"\"\"\n",
    "  Performs tournament selection on the contestants until the given number of selected contestants is reached;\n",
    "  note that `len(contestants)` needs to be a multiple of `tournament_size` and similarly for `num_to_select`\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  contestants : list\n",
    "    list of Node containing trees that undergo the selection\n",
    "  num_survivors : int\n",
    "    how many should be selected\n",
    "  tournament_size : int, optional\n",
    "    the size (window) of tournament selection (default is 4)\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  list\n",
    "    list containing (copies of) the trees that were selected\n",
    "  \"\"\"\n",
    "  selected = list()\n",
    "\n",
    "  n = len(contestants)\n",
    "  num_selected_per_parse = n // tournament_size\n",
    "  num_parses = num_to_select // num_selected_per_parse\n",
    "\n",
    "  # assert quantities are compatible\n",
    "  assert n / tournament_size == num_selected_per_parse, \"Number of contestants {} is not a multiple of tournament size {}\".format(n,tournament_size)\n",
    "  assert num_to_select / num_selected_per_parse == num_parses\n",
    " \n",
    "  def tournament():\n",
    "    # shuffle\n",
    "    temp = np.random.permutation(contestants)\n",
    "    fitnesses = np.array([t.fitness for t in temp])\n",
    "\n",
    "    winning_indices = np.argmax(fitnesses.reshape((-1, tournament_size)), axis=1)\n",
    "    winning_indices += np.arange(0, n, tournament_size)\n",
    "\n",
    "    return [deepcopy(temp[i]) for i in winning_indices]\n",
    "  \n",
    "  selected = Parallel(n_jobs=20)(delayed(tournament)() for _ in range(num_parses))\n",
    "#   for _ in range(num_parses):\n",
    "#     # shuffle\n",
    "#     np.random.shuffle(contestants)\n",
    "#     fitnesses = np.array([t.fitness for t in contestants])\n",
    "\n",
    "#     winning_indices = np.argmax(fitnesses.reshape((-1, tournament_size)), axis=1)\n",
    "#     winning_indices += np.arange(0, n, tournament_size)\n",
    "\n",
    "#     selected += [deepcopy(contestants[i]) for i in winning_indices]\n",
    "  selected = list(itertools.chain.from_iterable(selected))\n",
    "  # print(selected)\n",
    "  return selected\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes = leaf_nodes + [\n",
    "    AdaptiveConstant()\n",
    "]  # Think about the probability of sampling a coefficient\n",
    "internal_nodes = [\n",
    "    Plus(),\n",
    "    Minus(),\n",
    "    Times(),\n",
    "    Div(),\n",
    "    Square(),\n",
    "    Sqrt(),\n",
    "]  # Add your own operators here\n",
    "\n",
    "\n",
    "evo_adaptive = Evolution(\n",
    "    fitness_function_pt,\n",
    "    internal_nodes,\n",
    "    leaf_nodes,\n",
    "    4,\n",
    "    pop_size=64,\n",
    "    max_gens=5,\n",
    "    max_tree_size=40,\n",
    "    coeff_opts=[\n",
    "        {\n",
    "            \"fun\": coeff_adaptive_mutation,\n",
    "            \"rate\": 0.3, # rate of applying the mutation to the variation\n",
    "            \"prob\": 1, # probability of applying the mutation to the coefficient\n",
    "            \"gamma\": 0.15, # gamma parameter for the mutation (strength of the mutation)\n",
    "            \"epsilon\": 1e-16, # epsilon parameter for the mutation (minimum value of sigma)\n",
    "        }\n",
    "    ],\n",
    "    # selection={\"fun\":paralel_tournament_selection},\n",
    "    n_jobs=n_cores,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# evo_adaptive.evolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_score(tree, env):\n",
    "    rewards = []\n",
    "\n",
    "    for i in range(10):\n",
    "      # get initial state\n",
    "      observation = env.reset(seed=i)\n",
    "      observation = observation[0]\n",
    "\n",
    "      for _ in range(500):    \n",
    "        # build up the input sample for GP\n",
    "        input_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        # get output (squeezing because it is encapsulated in an array)\n",
    "        output = tree.get_output_pt(input_sample)\n",
    "        action = torch.argmax(output)\n",
    "        observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "        rewards.append(reward)\n",
    "\n",
    "\n",
    "        output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        if (terminated or truncated):\n",
    "            break\n",
    "\n",
    "    fitness = np.sum(rewards)\n",
    "    \n",
    "    return fitness\n",
    "# frames = []\n",
    "\n",
    "# gist to save gif from https://gist.github.com/botforge/64cbb71780e6208172bbf03cd9293553\n",
    "def save_frames_as_gif(frames, path='./', filename='evolved_lander.gif'):\n",
    "  plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "  patch = plt.imshow(frames[0])\n",
    "  plt.axis('off')\n",
    "  def animate(i):\n",
    "      patch.set_data(frames[i])\n",
    "  anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "  anim.save(path + filename, writer='imagemagick', fps=60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup experiment for self adaptive mutation\n",
    "\n",
    "run 7 test and one with the normal setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best = evo_adaptive.best_of_gens[-1]\n",
    "\n",
    "# print(best.get_readable_repr())\n",
    "# print(get_test_score(best))\n",
    "\n",
    "# frames = []\n",
    "# fitness_function_pt(best, num_episodes=1, episode_duration=500, render=True, ignore_done=False)\n",
    "# env.close()\n",
    "# save_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs per experiment: 5\n",
      "Number of paralell experiments: 4\n"
     ]
    }
   ],
   "source": [
    "experiments = []\n",
    "\n",
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes_adaptive = leaf_nodes + [AdaptiveConstant()]\n",
    "leaf_nodes_fixed = [Constant()]  # leaf_nodes + [Constant()]\n",
    "internal_nodes = [\n",
    "    Plus(),\n",
    "    Minus(),\n",
    "    Times(),\n",
    "    Div(),\n",
    "    Min(),\n",
    "    Max(),\n",
    "    Sin(),\n",
    "    # Square(),\n",
    "    # Sqrt(),\n",
    "]  # Add your own operators here\n",
    "\n",
    "n_trees = 4\n",
    "pop_size = 8  # 64\n",
    "max_tree_size = 40\n",
    "max_gens = 1  # 100\n",
    "\n",
    "optimization_batch_size = 64\n",
    "optimization_steps = 10\n",
    "optimization_lr = 0.01\n",
    "\n",
    "verbose = False\n",
    "\n",
    "n_paralell_experiments = 1 # parallel experiments don't seem to work\n",
    "n_jobs_per_experiment = n_cores // n_paralell_experiments\n",
    "\n",
    "n_runs_per_experiment = 5\n",
    "\n",
    "print(\n",
    "    f\"Number of jobs per experiment: {n_jobs_per_experiment}\\nNumber of paralell experiments: {n_paralell_experiments}\"\n",
    ")\n",
    "\n",
    "experiments = []\n",
    "\n",
    "# default experiement\n",
    "experiments.append(\n",
    "    {\n",
    "        \"description\": \"basline experiment\",\n",
    "        \"evo_args\": dict(\n",
    "            # fitness_function=fitness_function_pt,\n",
    "            internal_nodes=internal_nodes,\n",
    "            leaf_nodes=leaf_nodes_fixed,\n",
    "            n_trees=n_trees,\n",
    "            pop_size=pop_size,\n",
    "            max_gens=max_gens,\n",
    "            max_tree_size=max_tree_size,\n",
    "            # coeff_opts=[\n",
    "            #     {\n",
    "            #         \"fun\": coeff_mutation,\n",
    "            #         \"rate\": 0.5, # rate of applying the mutation to the variation\n",
    "            #         \"prob\": 1, # probability of applying the mutation to the coefficient\n",
    "            #         \"gamma\": 0.15, # gamma parameter for the mutation (strength of the mutation)\n",
    "            #         \"epsilon\": 1e-16, # epsilon parameter for the mutation (minimum value of sigma)\n",
    "            #     }\n",
    "            # ],\n",
    "            # selection={\"fun\":tournament_selection},\n",
    "            optimization_behavior=OptimizationBehavior.NONE,\n",
    "            batch_size=optimization_batch_size,\n",
    "            steps=optimization_steps,\n",
    "            lr=optimization_lr,\n",
    "            n_jobs=n_jobs_per_experiment,\n",
    "            verbose=verbose,\n",
    "            # n_runs_per_experiment=n_runs_per_experiment,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "#Optimization experiments\n",
    "\n",
    "# experiments.append(\n",
    "#     {\n",
    "#         \"description\": \"optimize all individuals\",\n",
    "#         \"evo_args\": dict(\n",
    "#             # fitness_function=fitness_function_pt,\n",
    "#             internal_nodes=internal_nodes,\n",
    "#             leaf_nodes=leaf_nodes_fixed,\n",
    "#             n_trees=n_trees,\n",
    "#             pop_size=pop_size,\n",
    "#             max_gens=max_gens,\n",
    "#             max_tree_size=max_tree_size,\n",
    "#             # coeff_opts=[\n",
    "#             #     {\n",
    "#             #         \"fun\": coeff_mutation,\n",
    "#             #         \"rate\": 0.5, # rate of applying the mutation to the variation\n",
    "#             #         \"prob\": 1, # probability of applying the mutation to the coefficient\n",
    "#             #         \"gamma\": 0.15, # gamma parameter for the mutation (strength of the mutation)\n",
    "#             #         \"epsilon\": 1e-16, # epsilon parameter for the mutation (minimum value of sigma)\n",
    "#             #     }\n",
    "#             # ],\n",
    "#             # selection={\"fun\":tournament_selection},\n",
    "#             optimization_behavior=OptimizationBehavior.ALL_INDIVIDUALS,\n",
    "#             batch_size=optimization_batch_size,\n",
    "#             steps=optimization_steps,\n",
    "#             lr=optimization_lr,\n",
    "#             n_jobs=n_jobs_per_experiment,\n",
    "#             verbose=verbose,\n",
    "#             # n_runs_per_experiment=n_runs_per_experiment,\n",
    "#         ),\n",
    "#     }\n",
    "# )\n",
    "# experiments.append(\n",
    "#     {\n",
    "#         \"description\": \"optimize all offspring\",\n",
    "#         \"evo_args\": dict(\n",
    "#             # fitness_function=fitness_function_pt,\n",
    "#             internal_nodes=internal_nodes,\n",
    "#             leaf_nodes=leaf_nodes_fixed,\n",
    "#             n_trees=n_trees,\n",
    "#             pop_size=pop_size,\n",
    "#             max_gens=max_gens,\n",
    "#             max_tree_size=max_tree_size,\n",
    "#             # coeff_opts=[\n",
    "#             #     {\n",
    "#             #         \"fun\": coeff_mutation,\n",
    "#             #         \"rate\": 0.5, # rate of applying the mutation to the variation\n",
    "#             #         \"prob\": 1, # probability of applying the mutation to the coefficient\n",
    "#             #         \"gamma\": 0.15, # gamma parameter for the mutation (strength of the mutation)\n",
    "#             #         \"epsilon\": 1e-16, # epsilon parameter for the mutation (minimum value of sigma)\n",
    "#             #     }\n",
    "#             # ],\n",
    "#             # selection={\"fun\":tournament_selection},\n",
    "#             optimization_behavior=OptimizationBehavior.ALL_OFFSPRING,\n",
    "#             batch_size=optimization_batch_size,\n",
    "#             steps=optimization_steps,\n",
    "#             lr=optimization_lr,\n",
    "#             n_jobs=n_jobs_per_experiment,\n",
    "#             verbose=verbose,\n",
    "#             # n_runs_per_experiment=n_runs_per_experiment,\n",
    "#         ),\n",
    "#     }\n",
    "# )\n",
    "# experiments.append(\n",
    "#     {\n",
    "#         \"description\": \"optimize all parents\",\n",
    "#         \"evo_args\": dict(\n",
    "#             # fitness_function=fitness_function_pt,\n",
    "#             internal_nodes=internal_nodes,\n",
    "#             leaf_nodes=leaf_nodes_fixed,\n",
    "#             n_trees=n_trees,\n",
    "#             pop_size=pop_size,\n",
    "#             max_gens=max_gens,\n",
    "#             max_tree_size=max_tree_size,\n",
    "#             # coeff_opts=[\n",
    "#             #     {\n",
    "#             #         \"fun\": coeff_mutation,\n",
    "#             #         \"rate\": 0.5, # rate of applying the mutation to the variation\n",
    "#             #         \"prob\": 1, # probability of applying the mutation to the coefficient\n",
    "#             #         \"gamma\": 0.15, # gamma parameter for the mutation (strength of the mutation)\n",
    "#             #         \"epsilon\": 1e-16, # epsilon parameter for the mutation (minimum value of sigma)\n",
    "#             #     }\n",
    "#             # ],\n",
    "#             # selection={\"fun\":tournament_selection},\n",
    "#             optimization_behavior=OptimizationBehavior.ALL_PARENTS,\n",
    "#             batch_size=optimization_batch_size,\n",
    "#             steps=optimization_steps,\n",
    "#             lr=optimization_lr,\n",
    "#             n_jobs=n_jobs_per_experiment,\n",
    "#             verbose=verbose,\n",
    "#             # n_runs_per_experiment=n_runs_per_experiment,\n",
    "#         ),\n",
    "#     }\n",
    "# )\n",
    "# experiments.append(\n",
    "#     {\n",
    "#         \"description\": \"optimize sampled individuals\",\n",
    "#         \"evo_args\": dict(\n",
    "#             # fitness_function=fitness_function_pt,\n",
    "#             internal_nodes=internal_nodes,\n",
    "#             leaf_nodes=leaf_nodes_fixed,\n",
    "#             n_trees=n_trees,\n",
    "#             pop_size=pop_size,\n",
    "#             max_gens=max_gens,\n",
    "#             max_tree_size=max_tree_size,\n",
    "#             # coeff_opts=[\n",
    "#             #     {\n",
    "#             #         \"fun\": coeff_mutation,\n",
    "#             #         \"rate\": 0.5, # rate of applying the mutation to the variation\n",
    "#             #         \"prob\": 1, # probability of applying the mutation to the coefficient\n",
    "#             #         \"gamma\": 0.15, # gamma parameter for the mutation (strength of the mutation)\n",
    "#             #         \"epsilon\": 1e-16, # epsilon parameter for the mutation (minimum value of sigma)\n",
    "#             #     }\n",
    "#             # ],\n",
    "#             # selection={\"fun\":tournament_selection},\n",
    "#             optimization_behavior=OptimizationBehavior.SAMPLED_INDIVIDUALS,\n",
    "#             batch_size=optimization_batch_size,\n",
    "#             steps=optimization_steps,\n",
    "#             lr=optimization_lr,\n",
    "#             n_jobs=n_jobs_per_experiment,\n",
    "#             verbose=verbose,\n",
    "#             # n_runs_per_experiment=n_runs_per_experiment,\n",
    "#         ),\n",
    "#     }\n",
    "# )\n",
    "# experiments.append(\n",
    "#     {\n",
    "#         \"description\": \"optimize sampled offspring\",\n",
    "#         \"evo_args\": dict(\n",
    "#             # fitness_function=fitness_function_pt,\n",
    "#             internal_nodes=internal_nodes,\n",
    "#             leaf_nodes=leaf_nodes_fixed,\n",
    "#             n_trees=n_trees,\n",
    "#             pop_size=pop_size,\n",
    "#             max_gens=max_gens,\n",
    "#             max_tree_size=max_tree_size,\n",
    "#             # coeff_opts=[\n",
    "#             #     {\n",
    "#             #         \"fun\": coeff_mutation,\n",
    "#             #         \"rate\": 0.5, # rate of applying the mutation to the variation\n",
    "#             #         \"prob\": 1, # probability of applying the mutation to the coefficient\n",
    "#             #         \"gamma\": 0.15, # gamma parameter for the mutation (strength of the mutation)\n",
    "#             #         \"epsilon\": 1e-16, # epsilon parameter for the mutation (minimum value of sigma)\n",
    "#             #     }\n",
    "#             # ],\n",
    "#             # selection={\"fun\":tournament_selection},\n",
    "#             optimization_behavior=OptimizationBehavior.SAMPLED_OFFSPRING,\n",
    "#             batch_size=optimization_batch_size,\n",
    "#             steps=optimization_steps,\n",
    "#             lr=optimization_lr,\n",
    "#             n_jobs=n_jobs_per_experiment,\n",
    "#             verbose=verbose,\n",
    "#             # n_runs_per_experiment=n_runs_per_experiment,\n",
    "#         ),\n",
    "#     }\n",
    "# )\n",
    "# experiments.append(\n",
    "#     {\n",
    "#         \"description\": \"optimize sampled parents\",\n",
    "#         \"evo_args\": dict(\n",
    "#             # fitness_function=fitness_function_pt,\n",
    "#             internal_nodes=internal_nodes,\n",
    "#             leaf_nodes=leaf_nodes_fixed,\n",
    "#             n_trees=n_trees,\n",
    "#             pop_size=pop_size,\n",
    "#             max_gens=max_gens,\n",
    "#             max_tree_size=max_tree_size,\n",
    "#             # coeff_opts=[\n",
    "#             #     {\n",
    "#             #         \"fun\": coeff_mutation,\n",
    "#             #         \"rate\": 0.5, # rate of applying the mutation to the variation\n",
    "#             #         \"prob\": 1, # probability of applying the mutation to the coefficient\n",
    "#             #         \"gamma\": 0.15, # gamma parameter for the mutation (strength of the mutation)\n",
    "#             #         \"epsilon\": 1e-16, # epsilon parameter for the mutation (minimum value of sigma)\n",
    "#             #     }\n",
    "#             # ],\n",
    "#             # selection={\"fun\":tournament_selection},\n",
    "#             optimization_behavior=OptimizationBehavior.SAMPLED_PARENTS,\n",
    "#             batch_size=optimization_batch_size,\n",
    "#             steps=optimization_steps,\n",
    "#             lr=optimization_lr,\n",
    "#             n_jobs=n_jobs_per_experiment,\n",
    "#             verbose=verbose,\n",
    "#             # n_runs_per_experiment=n_runs_per_experiment,\n",
    "#         ),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# adaptive experiments\n",
    "\n",
    "experiments.append(\n",
    "    {\n",
    "        \"descirption\": \"adaptive mutation, prob:1.0 , gamma:0.15\",\n",
    "        \"evo_args\": dict(\n",
    "            # fitness_function=fitness_function_pt,\n",
    "            internal_nodes=internal_nodes,\n",
    "            leaf_nodes=leaf_nodes_adaptive,\n",
    "            n_trees=n_trees,\n",
    "            pop_size=pop_size,\n",
    "            max_gens=max_gens,\n",
    "            max_tree_size=max_tree_size,\n",
    "            coeff_opts=[\n",
    "                {\n",
    "                    \"fun\": coeff_adaptive_mutation,\n",
    "                    \"rate\": 0.5,  # rate of applying the mutation to the variation\n",
    "                    \"prob\": 1,  # probability of applying the mutation to the coefficient\n",
    "                    \"gamma\": 0.15,  # gamma parameter for the mutation (strength of the mutation)\n",
    "                    \"epsilon\": 1e-16,  # epsilon parameter for the mutation (minimum value of sigma)\n",
    "                }\n",
    "            ],\n",
    "            # selection={\"fun\":tournament_selection},\n",
    "            optimization_behavior=OptimizationBehavior.NONE,\n",
    "            batch_size=optimization_batch_size,\n",
    "            steps=optimization_steps,\n",
    "            lr=optimization_lr,\n",
    "            n_jobs=n_jobs_per_experiment,\n",
    "            verbose=verbose,\n",
    "            # n_runs_per_experiment=n_runs_per_experiment,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "experiments.append(\n",
    "    {\n",
    "        \"descirption\": \"adaptive mutation, prob:1.0 , gamma:0.1\",\n",
    "        \"evo_args\": dict(\n",
    "            # fitness_function=fitness_function_pt,\n",
    "            internal_nodes=internal_nodes,\n",
    "            leaf_nodes=leaf_nodes_adaptive,\n",
    "            n_trees=n_trees,\n",
    "            pop_size=pop_size,\n",
    "            max_gens=max_gens,\n",
    "            max_tree_size=max_tree_size,\n",
    "            coeff_opts=[\n",
    "                {\n",
    "                    \"fun\": coeff_adaptive_mutation,\n",
    "                    \"rate\": 0.5,  # rate of applying the mutation to the variation\n",
    "                    \"prob\": 1,  # probability of applying the mutation to the coefficient\n",
    "                    \"gamma\": 0.1,  # gamma parameter for the mutation (strength of the mutation)\n",
    "                    \"epsilon\": 1e-16,  # epsilon parameter for the mutation (minimum value of sigma)\n",
    "                }\n",
    "            ],\n",
    "            # selection={\"fun\":tournament_selection},\n",
    "            optimization_behavior=OptimizationBehavior.NONE,\n",
    "            batch_size=optimization_batch_size,\n",
    "            steps=optimization_steps,\n",
    "            lr=optimization_lr,\n",
    "            n_jobs=n_jobs_per_experiment,\n",
    "            verbose=verbose,\n",
    "            # n_runs_per_experiment=n_runs_per_experiment,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "experiments.append(\n",
    "    {\n",
    "        \"descirption\": \"adaptive mutation, prob:1.0 , gamma:0.05\",\n",
    "        \"evo_args\": dict(\n",
    "            # fitness_function=fitness_function_pt,\n",
    "            internal_nodes=internal_nodes,\n",
    "            leaf_nodes=leaf_nodes_adaptive,\n",
    "            n_trees=n_trees,\n",
    "            pop_size=pop_size,\n",
    "            max_gens=max_gens,\n",
    "            max_tree_size=max_tree_size,\n",
    "            coeff_opts=[\n",
    "                {\n",
    "                    \"fun\": coeff_adaptive_mutation,\n",
    "                    \"rate\": 0.5,  # rate of applying the mutation to the variation\n",
    "                    \"prob\": 1,  # probability of applying the mutation to the coefficient\n",
    "                    \"gamma\": 0.05,  # gamma parameter for the mutation (strength of the mutation)\n",
    "                    \"epsilon\": 1e-16,  # epsilon parameter for the mutation (minimum value of sigma)\n",
    "                }\n",
    "            ],\n",
    "            # selection={\"fun\":tournament_selection},\n",
    "            optimization_behavior=OptimizationBehavior.NONE,\n",
    "            batch_size=optimization_batch_size,\n",
    "            steps=optimization_steps,\n",
    "            lr=optimization_lr,\n",
    "            n_jobs=n_jobs_per_experiment,\n",
    "            verbose=verbose,\n",
    "            # n_runs_per_experiment=n_runs_per_experiment,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "experiments.append(\n",
    "    {\n",
    "        \"descirption\": \"adaptive mutation, prob:1.0 , gamma:0.2\",\n",
    "        \"evo_args\": dict(\n",
    "            # fitness_function=fitness_function_pt,\n",
    "            internal_nodes=internal_nodes,\n",
    "            leaf_nodes=leaf_nodes_adaptive,\n",
    "            n_trees=n_trees,\n",
    "            pop_size=pop_size,\n",
    "            max_gens=max_gens,\n",
    "            max_tree_size=max_tree_size,\n",
    "            coeff_opts=[\n",
    "                {\n",
    "                    \"fun\": coeff_adaptive_mutation,\n",
    "                    \"rate\": 0.5,  # rate of applying the mutation to the variation\n",
    "                    \"prob\": 1,  # probability of applying the mutation to the coefficient\n",
    "                    \"gamma\": 0.2,  # gamma parameter for the mutation (strength of the mutation)\n",
    "                    \"epsilon\": 1e-16,  # epsilon parameter for the mutation (minimum value of sigma)\n",
    "                }\n",
    "            ],\n",
    "            # selection={\"fun\":tournament_selection},\n",
    "            optimization_behavior=OptimizationBehavior.NONE,\n",
    "            batch_size=optimization_batch_size,\n",
    "            steps=optimization_steps,\n",
    "            lr=optimization_lr,\n",
    "            n_jobs=n_jobs_per_experiment,\n",
    "            verbose=verbose,\n",
    "            # n_runs_per_experiment=n_runs_per_experiment,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "experiments.append(\n",
    "    {\n",
    "        \"descirption\": \"adaptive mutation, prob:0.75 , gamma:0.15\",\n",
    "        \"evo_args\": dict(\n",
    "            # fitness_function=fitness_function_pt,\n",
    "            internal_nodes=internal_nodes,\n",
    "            leaf_nodes=leaf_nodes_adaptive,\n",
    "            n_trees=n_trees,\n",
    "            pop_size=pop_size,\n",
    "            max_gens=max_gens,\n",
    "            max_tree_size=max_tree_size,\n",
    "            coeff_opts=[\n",
    "                {\n",
    "                    \"fun\": coeff_adaptive_mutation,\n",
    "                    \"rate\": 0.5,  # rate of applying the mutation to the variation\n",
    "                    \"prob\": 0.75,  # probability of applying the mutation to the coefficient\n",
    "                    \"gamma\": 0.2,  # gamma parameter for the mutation (strength of the mutation)\n",
    "                    \"epsilon\": 1e-16,  # epsilon parameter for the mutation (minimum value of sigma)\n",
    "                }\n",
    "            ],\n",
    "            # selection={\"fun\":tournament_selection},\n",
    "            optimization_behavior=OptimizationBehavior.NONE,\n",
    "            batch_size=optimization_batch_size,\n",
    "            steps=optimization_steps,\n",
    "            lr=optimization_lr,\n",
    "            n_jobs=n_jobs_per_experiment,\n",
    "            verbose=verbose,\n",
    "            # n_runs_per_experiment=n_runs_per_experiment,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "experiments.append(\n",
    "    {\n",
    "        \"descirption\": \"adaptive mutation, prob:0.5 , gamma:0.15\",\n",
    "        \"evo_args\": dict(\n",
    "            # fitness_function=fitness_function_pt,\n",
    "            internal_nodes=internal_nodes,\n",
    "            leaf_nodes=leaf_nodes_adaptive,\n",
    "            n_trees=n_trees,\n",
    "            pop_size=pop_size,\n",
    "            max_gens=max_gens,\n",
    "            max_tree_size=max_tree_size,\n",
    "            coeff_opts=[\n",
    "                {\n",
    "                    \"fun\": coeff_adaptive_mutation,\n",
    "                    \"rate\": 0.5,  # rate of applying the mutation to the variation\n",
    "                    \"prob\": 0.5,  # probability of applying the mutation to the coefficient\n",
    "                    \"gamma\": 0.15,  # gamma parameter for the mutation (strength of the mutation)\n",
    "                    \"epsilon\": 1e-16,  # epsilon parameter for the mutation (minimum value of sigma)\n",
    "                }\n",
    "            ],\n",
    "            # selection={\"fun\":tournament_selection},\n",
    "            optimization_behavior=OptimizationBehavior.NONE,\n",
    "            batch_size=optimization_batch_size,\n",
    "            steps=optimization_steps,\n",
    "            lr=optimization_lr,\n",
    "            n_jobs=n_jobs_per_experiment,\n",
    "            verbose=verbose,\n",
    "            # n_runs_per_experiment=n_runs_per_experiment,\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "def run_experiment(exp, i):\n",
    "    print(\"Running experiment\", i)\n",
    "    # setup new environment\n",
    "    # import gym\n",
    "\n",
    "    exp = copy.deepcopy(exp)\n",
    "\n",
    "    env_internal = gym.make(\"LunarLander-v2\", render_mode=None)\n",
    "    env_internal.reset()\n",
    "    # env_internal.render_mode = None\n",
    "\n",
    "\n",
    "    num_features = env.observation_space.shape[0]\n",
    "    leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "    exp[\"evo_args\"][\"leaf_nodes\"] = leaf_nodes + exp[\"evo_args\"][\"leaf_nodes\"]\n",
    "    frames = []\n",
    "\n",
    "    def internal_fitness_function_pt(\n",
    "        multitree, num_episodes=5, episode_duration=300, render=False, ignore_done=False\n",
    "    ):\n",
    "        memory = ReplayMemory(10000)\n",
    "        rewards = []\n",
    "\n",
    "        for _ in range(num_episodes):\n",
    "            # get initial state of the environment\n",
    "            observation = env_internal.reset()\n",
    "            observation = observation[0]\n",
    "\n",
    "            for _ in range(episode_duration):\n",
    "                if render:\n",
    "                    frames.append(env_internal.render())\n",
    "\n",
    "                input_sample = torch.from_numpy(observation.reshape((1, -1))).float()\n",
    "\n",
    "                # what goes here? TODO\n",
    "                action = torch.argmax(multitree.get_output_pt(input_sample))\n",
    "                observation, reward, terminated, truncated, info = env_internal.step(action.item())\n",
    "                rewards.append(reward)\n",
    "                output_sample = torch.from_numpy(observation.reshape((1, -1))).float()\n",
    "                memory.push(\n",
    "                    input_sample,\n",
    "                    torch.tensor([[action.item()]]),\n",
    "                    output_sample,\n",
    "                    torch.tensor([reward]),\n",
    "                )\n",
    "                if (terminated or truncated) and not ignore_done:\n",
    "                    break\n",
    "\n",
    "        fitness = np.sum(rewards)\n",
    "\n",
    "        return fitness, memory\n",
    "    exp[\"evo_args\"][\"fitness_function\"] = internal_fitness_function_pt\n",
    "\n",
    "    \n",
    "    results= copy.deepcopy(exp)\n",
    "    for i in range(2):\n",
    "        results[i] = {}\n",
    "        evo = Evolution(**exp[\"evo_args\"])\n",
    "        evo.evolve()\n",
    "        results[i][\"fitness\"] = []\n",
    "        for j, best_of_gen in enumerate(evo.best_of_gens):\n",
    "            results[i][\"fitness\"].append(best_of_gen.fitness)\n",
    "\n",
    "        best = evo.best_of_gens[-1]\n",
    "        results[i][\"test_score\"] = get_test_score(best, env_internal)\n",
    "    results[\"evo_args\"][\"fitness_function\"] = \"\"\n",
    "    results[\"evo_args\"][\"optimization_behavior\"] = results[\"experiment\"][\n",
    "        \"optimization_behavior\"\n",
    "    ].name\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments\n",
      "total number of experiments 4\n",
      "[{'description': 'basline experiment', 'evo_args': {'internal_nodes': [+, -, *, /, min, max, sin], 'leaf_nodes': [const?], 'n_trees': 4, 'pop_size': 8, 'max_gens': 1, 'max_tree_size': 40, 'optimization_behavior': <OptimizationBehavior.NONE: 0>, 'batch_size': 64, 'steps': 10, 'lr': 0.01, 'n_jobs': 5, 'verbose': False}}, {'descirption': 'adaptive mutation, prob:1.0 , gamma:0.15', 'evo_args': {'internal_nodes': [+, -, *, /, min, max, sin], 'leaf_nodes': [x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7, const?], 'n_trees': 4, 'pop_size': 8, 'max_gens': 1, 'max_tree_size': 40, 'coeff_opts': [{'fun': <function coeff_adaptive_mutation at 0x00000212B64FF380>, 'rate': 0.5, 'prob': 1, 'gamma': 0.15, 'epsilon': 1e-16}], 'optimization_behavior': <OptimizationBehavior.NONE: 0>, 'batch_size': 64, 'steps': 10, 'lr': 0.01, 'n_jobs': 5, 'verbose': False}}, {'descirption': 'adaptive mutation, prob:1.0 , gamma:0.1', 'evo_args': {'internal_nodes': [+, -, *, /, min, max, sin], 'leaf_nodes': [x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7, const?], 'n_trees': 4, 'pop_size': 8, 'max_gens': 1, 'max_tree_size': 40, 'coeff_opts': [{'fun': <function coeff_adaptive_mutation at 0x00000212B64FF380>, 'rate': 0.5, 'prob': 1, 'gamma': 0.1, 'epsilon': 1e-16}], 'optimization_behavior': <OptimizationBehavior.NONE: 0>, 'batch_size': 64, 'steps': 10, 'lr': 0.01, 'n_jobs': 5, 'verbose': False}}, {'descirption': 'adaptive mutation, prob:1.0 , gamma:0.05', 'evo_args': {'internal_nodes': [+, -, *, /, min, max, sin], 'leaf_nodes': [x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7, const?], 'n_trees': 4, 'pop_size': 8, 'max_gens': 1, 'max_tree_size': 40, 'coeff_opts': [{'fun': <function coeff_adaptive_mutation at 0x00000212B64FF380>, 'rate': 0.5, 'prob': 1, 'gamma': 0.05, 'epsilon': 1e-16}], 'optimization_behavior': <OptimizationBehavior.NONE: 0>, 'batch_size': 64, 'steps': 10, 'lr': 0.01, 'n_jobs': 5, 'verbose': False}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "m_bodyCount > 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\njoblib.externals.loky.process_executor._RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\_utils.py\", line 72, in __call__\n    return self.func(**kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\rvoor\\AppData\\Local\\Temp\\ipykernel_2848\\3378123252.py\", line 29, in internal_fitness_function_pt\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\gymnasium\\wrappers\\time_limit.py\", line 75, in reset\n    return self.env.reset(**kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py\", line 61, in reset\n    return self.env.reset(**kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py\", line 59, in reset\n    return self.env.reset(**kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\gymnasium\\envs\\box2d\\lunar_lander.py\", line 352, in reset\n    self._destroy()\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\gymnasium\\envs\\box2d\\lunar_lander.py\", line 342, in _destroy\n    self.world.DestroyBody(self.legs[0])\nAssertionError: m_bodyCount > 0\n\"\"\"\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\rvoor\\AppData\\Local\\Temp\\ipykernel_2848\\3378123252.py\", line 62, in run_experiment\n  File \"c:\\Users\\rvoor\\OneDrive\\Study\\Msc Robotics\\CS4205 - Evolutionary Algorithms\\project\\ea_lunarlander\\genepro\\evo.py\", line 338, in evolve\n    self._perform_generation()\n  File \"c:\\Users\\rvoor\\OneDrive\\Study\\Msc Robotics\\CS4205 - Evolutionary Algorithms\\project\\ea_lunarlander\\genepro\\evo.py\", line 260, in _perform_generation\n    fitnesses = Parallel(n_jobs=self.n_jobs)(delayed(self.fitness_function)(t) for t in offspring_population)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py\", line 2007, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py\", line 1650, in _get_outputs\n    yield from self._retrieve()\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py\", line 1754, in _retrieve\n    self._raise_error_fast()\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py\", line 1789, in _raise_error_fast\n    error_job.get_result(self.timeout)\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py\", line 745, in get_result\n    return self._return_or_raise()\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py\", line 763, in _return_or_raise\n    raise self._result\nAssertionError: m_bodyCount > 0\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal number of experiments\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(experiments)) \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(experiments) \n\u001b[1;32m----> 4\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_paralell_experiments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_experiment\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexperiments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rvoor\\miniconda3\\envs\\ea\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mAssertionError\u001b[0m: m_bodyCount > 0"
     ]
    }
   ],
   "source": [
    "print(\"Running experiments\")\n",
    "print(\"total number of experiments\", len(experiments)) \n",
    "print(experiments) \n",
    "\n",
    "all_results = Parallel(n_jobs=n_paralell_experiments,  verbose=True)(delayed(run_experiment)(exp, i) for i, exp in enumerate(experiments))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'experiment': {'internal_nodes': [+, -, *, /, min, max, sin],\n",
       "   'leaf_nodes': [x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7, const?],\n",
       "   'n_trees': 4,\n",
       "   'pop_size': 24,\n",
       "   'max_gens': 1,\n",
       "   'max_tree_size': 40,\n",
       "   'optimization_behavior': 'NONE',\n",
       "   'batch_size': 64,\n",
       "   'steps': 10,\n",
       "   'lr': 0.01,\n",
       "   'n_jobs': 5,\n",
       "   'verbose': False,\n",
       "   'fitness_function': ''},\n",
       "  0: {'fitness': [-606.2512963638274, -650.0489471314343],\n",
       "   'test_score': -2465.945566708634},\n",
       "  1: {'fitness': [-716.4773488986508, -1327.5684942240428],\n",
       "   'test_score': -2249.9315920654867}},\n",
       " {'experiment': {'internal_nodes': [+, -, *, /, min, max, sin],\n",
       "   'leaf_nodes': [x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7, const?],\n",
       "   'n_trees': 4,\n",
       "   'pop_size': 24,\n",
       "   'max_gens': 1,\n",
       "   'max_tree_size': 40,\n",
       "   'optimization_behavior': 'ALL_INDIVIDUALS',\n",
       "   'batch_size': 64,\n",
       "   'steps': 10,\n",
       "   'lr': 0.01,\n",
       "   'n_jobs': 5,\n",
       "   'verbose': False,\n",
       "   'fitness_function': ''},\n",
       "  0: {'fitness': [-456.12006603882566, -702.8624309880677],\n",
       "   'test_score': -1138.4459065544424},\n",
       "  1: {'fitness': [-593.0654885476822, -907.0838498675466],\n",
       "   'test_score': -9012.923140791187}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'experiment': {'internal_nodes': [+, -, *, /, min, max, sin],\n",
       "   'leaf_nodes': [x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7, const?],\n",
       "   'n_trees': 4,\n",
       "   'pop_size': 24,\n",
       "   'max_gens': 1,\n",
       "   'max_tree_size': 40,\n",
       "   'optimization_behavior': 'NONE',\n",
       "   'batch_size': 64,\n",
       "   'steps': 10,\n",
       "   'lr': 0.01,\n",
       "   'n_jobs': 5,\n",
       "   'verbose': False,\n",
       "   'fitness_function': ''},\n",
       "  0: {'fitness': [-606.2512963638274, -650.0489471314343],\n",
       "   'test_score': -2465.945566708634},\n",
       "  1: {'fitness': [-716.4773488986508, -1327.5684942240428],\n",
       "   'test_score': -2249.9315920654867}},\n",
       " {'experiment': {'internal_nodes': [+, -, *, /, min, max, sin],\n",
       "   'leaf_nodes': [x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7, const?],\n",
       "   'n_trees': 4,\n",
       "   'pop_size': 24,\n",
       "   'max_gens': 1,\n",
       "   'max_tree_size': 40,\n",
       "   'optimization_behavior': 'ALL_INDIVIDUALS',\n",
       "   'batch_size': 64,\n",
       "   'steps': 10,\n",
       "   'lr': 0.01,\n",
       "   'n_jobs': 5,\n",
       "   'verbose': False,\n",
       "   'fitness_function': ''},\n",
       "  0: {'fitness': [-456.12006603882566, -702.8624309880677],\n",
       "   'test_score': -1138.4459065544424},\n",
       "  1: {'fitness': [-593.0654885476822, -907.0838498675466],\n",
       "   'test_score': -9012.923140791187}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_results = None\n",
    "with open(\"results.pkl\", \"rb\") as f:\n",
    "    loaded_results = pickle.load(f)\n",
    "\n",
    "loaded_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
